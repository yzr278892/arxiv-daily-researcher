"""
ç ”ç©¶æŠ¥å‘Šç”ŸæˆAgentï¼ˆæ¨¡å—åŒ–ç‰ˆæœ¬ï¼‰

æ”¯æŒé€šè¿‡JSONæ¨¡æ¿é…ç½®æŠ¥å‘Šçš„ç»“æ„å’Œæ ¼å¼ï¼š
- åŸºæœ¬æŠ¥å‘Šï¼šæ¯ç¯‡è®ºæ–‡çš„å…ƒæ•°æ®ã€æ‘˜è¦ã€TLDRã€è¯„åˆ†ç­‰
- æ·±åº¦åˆ†ææŠ¥å‘Šï¼šåŠæ ¼è®ºæ–‡çš„è¯¦ç»†åˆ†æ

æ¨¡å—åŒ–è®¾è®¡ï¼š
- æ¯ä¸ªä¿¡æ¯å—ä½œä¸ºç‹¬ç«‹æ¨¡å—
- å¯é…ç½®æ¨¡å—çš„å¯ç”¨/ç¦ç”¨ã€é¡ºåºã€æ ¼å¼ã€æŠ˜å ç­‰
- æ”¯æŒè‡ªå®šä¹‰æç¤ºè¯
"""

import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

from config import settings
from .report_modules.base_module import FormatHelper
from .report_modules.renderers import ModuleRendererFactory

logger = logging.getLogger(__name__)

# æ•°æ®æºæ˜¾ç¤ºåç§°æ˜ å°„
SOURCE_DISPLAY_NAMES = {
    "arxiv": "ArXiv",
    "prl": "Physical Review Letters",
    "pra": "Physical Review A",
    "prb": "Physical Review B",
    "prc": "Physical Review C",
    "prd": "Physical Review D",
    "pre": "Physical Review E",
    "prx": "Physical Review X",
    "prxq": "PRX Quantum",
    "rmp": "Reviews of Modern Physics",
    "nature": "Nature",
    "nature_physics": "Nature Physics",
    "nature_communications": "Nature Communications",
    "science": "Science",
    "science_advances": "Science Advances",
    "npj_quantum_information": "npj Quantum Information",
    "quantum": "Quantum",
    "new_journal_of_physics": "New Journal of Physics",
}


class Reporter:
    """
    ç ”ç©¶æŠ¥å‘Šç”ŸæˆAgentï¼ˆæ¨¡å—åŒ–ç‰ˆæœ¬ï¼‰ã€‚

    èŒè´£:
    - åŠ è½½æŠ¥å‘Šæ¨¡æ¿é…ç½®
    - æŒ‰æ•°æ®æºåˆ†åˆ«ç”ŸæˆæŠ¥å‘Š
    - ä½¿ç”¨æ¨¡å—åŒ–æ¸²æŸ“å™¨ç”Ÿæˆå„éƒ¨åˆ†å†…å®¹
    - æ”¯æŒè‡ªå®šä¹‰æ ¼å¼å’Œå¸ƒå±€
    """

    def __init__(self):
        self.report_base_dir = settings.REPORTS_DIR

        # åŠ è½½æ¨¡æ¿
        self.basic_template = settings.load_report_template("basic_report_template.json")
        self.deep_template = settings.load_report_template("deep_analysis_template.json")

        # åˆå§‹åŒ–æ ¼å¼åŒ–å·¥å…·å’Œæ¸²æŸ“å™¨å·¥å‚
        admonition_style = self.basic_template.get('global', {}).get('admonition_style', 'mkdocs')
        self.format_helper = FormatHelper(admonition_style)
        self.renderer_factory = ModuleRendererFactory(self.format_helper, self.deep_template)

    def get_source_display_name(self, source: str) -> str:
        """è·å–æ•°æ®æºçš„æ˜¾ç¤ºåç§°"""
        return SOURCE_DISPLAY_NAMES.get(source, source.upper())

    def generate_reports_by_source(
        self,
        scored_papers_by_source: Dict[str, List[Dict[str, Any]]],
        keywords_dict: Dict[str, float],
        analyses_by_source: Dict[str, List[Dict[str, Any]]] = None
    ) -> Dict[str, Path]:
        """
        æŒ‰æ•°æ®æºç”Ÿæˆåˆ†å¼€çš„æŠ¥å‘Šã€‚

        å‚æ•°:
            scored_papers_by_source: {æ•°æ®æº: è®ºæ–‡åˆ—è¡¨}
            keywords_dict: å…³é”®è¯-æƒé‡å­—å…¸
            analyses_by_source: {æ•°æ®æº: æ·±åº¦åˆ†æåˆ—è¡¨}ï¼ˆå¯é€‰ï¼‰

        è¿”å›:
            Dict[str, Path]: {æ•°æ®æº: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„}
        """
        if analyses_by_source is None:
            analyses_by_source = {}

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        report_paths = {}

        for source, papers in scored_papers_by_source.items():
            if not papers:
                continue

            # åˆ›å»ºæ•°æ®æºå­ç›®å½•
            if settings.REPORTS_BY_SOURCE:
                source_dir = self.report_base_dir / source
            else:
                source_dir = self.report_base_dir

            source_dir.mkdir(parents=True, exist_ok=True)

            # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
            display_name = self.get_source_display_name(source)
            filename = f"{source.upper()}_Report_{timestamp}.md"
            filepath = source_dir / filename

            # è·å–è¯¥æ•°æ®æºçš„æ·±åº¦åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
            analyses = analyses_by_source.get(source, [])
            # å¦‚æœè¯¥æ•°æ®æºæœ‰æ·±åº¦åˆ†æç»“æœï¼Œåˆ™æ˜¾ç¤ºæ·±åº¦åˆ†æ
            has_deep_analysis = len(analyses) > 0

            # ç”ŸæˆæŠ¥å‘Š
            self._generate_single_source_report(
                filepath=filepath,
                source=source,
                display_name=display_name,
                papers=papers,
                keywords_dict=keywords_dict,
                analyses=analyses,
                has_deep_analysis=has_deep_analysis
            )

            report_paths[source] = filepath
            logger.info(f"[{source}] æŠ¥å‘Šå·²ç”Ÿæˆ: {filepath}")

        return report_paths

    def _generate_single_source_report(
        self,
        filepath: Path,
        source: str,
        display_name: str,
        papers: List[Dict[str, Any]],
        keywords_dict: Dict[str, float],
        analyses: List[Dict[str, Any]],
        has_deep_analysis: bool
    ):
        """ç”Ÿæˆå•ä¸ªæ•°æ®æºçš„æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        today = datetime.now().strftime("%Y-%m-%d")

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_papers = len(papers)
        qualified_count = sum(1 for p in papers if p['score_response'].is_qualified)
        analyzed_count = len(analyses)

        total_weight = sum(keywords_dict.values())
        passing_score = settings.calculate_passing_score(total_weight)

        # æŒ‰æ€»åˆ†æ’åº
        sorted_papers = sorted(
            papers,
            key=lambda x: x['score_response'].total_score,
            reverse=True
        )

        # è·å–å¸ƒå±€é…ç½®
        layout = self.basic_template.get('layout', {})

        # å¼€å§‹ç”ŸæˆæŠ¥å‘Š
        lines = []

        # æŠ¥å‘Šæ ‡é¢˜
        title_template = layout.get('report_title_template', 'ğŸ“Š {source_name} ç ”ç©¶æŠ¥å‘Š ({date})')
        report_title = title_template.format(source_name=display_name, date=today)
        lines.append(f"# {report_title}")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {timestamp}")
        lines.append(f"> æ•°æ®æº: {display_name}")
        lines.append("")

        # æ•°æ®æºè¯´æ˜
        if source != "arxiv":
            lines.append("> âš ï¸ **æ³¨æ„**: è¯¥æ•°æ®æºä¸æ”¯æŒPDFä¸‹è½½ï¼Œä»…æä¾›è¯„åˆ†å’Œæ‘˜è¦ç¿»è¯‘ï¼Œæ— æ·±åº¦åˆ†æ")
            lines.append("")

        # ========== é…ç½®ä¿¡æ¯ ==========
        if layout.get('show_config_section', True):
            lines.extend(self._generate_config_section(keywords_dict, passing_score))

        # ========== ç»Ÿè®¡æ±‡æ€» ==========
        if layout.get('show_stats_section', True):
            lines.extend(self._generate_stats_section(
                total_papers, qualified_count, analyzed_count, has_deep_analysis
            ))

        # ========== åŠæ ¼è®ºæ–‡è¯¦ç»†ä¿¡æ¯ ==========
        if layout.get('show_qualified_section', True) and qualified_count > 0:
            section_title = layout.get('qualified_section_title', 'â­ åŠæ ¼è®ºæ–‡è¯¦ç»†åˆ†æ')
            lines.append(f"## {section_title}")
            lines.append("")

            qualified_papers = [p for p in sorted_papers if p['score_response'].is_qualified]

            for idx, paper in enumerate(qualified_papers, 1):
                paper_lines = self._render_paper_section(
                    paper, keywords_dict, analyses, idx, is_qualified_section=True
                )
                lines.extend(paper_lines)

        # ========== æ‰€æœ‰è®ºæ–‡è¯¦ç»†ä¿¡æ¯ ==========
        if layout.get('show_all_papers_section', True):
            section_title = layout.get('all_papers_section_title', 'ğŸ“‹ æ‰€æœ‰è®ºæ–‡åˆ—è¡¨')
            lines.append(f"## {section_title}")
            lines.append("")

            qualified_icon = layout.get('qualified_icon', 'âœ…')
            unqualified_icon = layout.get('unqualified_icon', 'âŒ')

            for idx, paper in enumerate(sorted_papers, 1):
                paper_lines = self._render_paper_section(
                    paper, keywords_dict, [], idx,
                    is_qualified_section=False,
                    qualified_icon=qualified_icon,
                    unqualified_icon=unqualified_icon
                )
                lines.extend(paper_lines)

        # å†™å…¥æ–‡ä»¶
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write('\n'.join(lines))
            logger.info(f"  - æ€»è®ºæ–‡æ•°: {total_papers}")
            logger.info(f"  - åŠæ ¼è®ºæ–‡: {qualified_count}")
            if has_deep_analysis:
                logger.info(f"  - æ·±åº¦åˆ†æ: {analyzed_count}")
        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def _generate_config_section(
        self,
        keywords_dict: Dict[str, float],
        passing_score: float
    ) -> List[str]:
        """ç”Ÿæˆé…ç½®ä¿¡æ¯éƒ¨åˆ†"""
        lines = []
        total_weight = sum(keywords_dict.values())

        lines.append("## ğŸ“Œ é…ç½®ä¿¡æ¯")
        lines.append("")

        # å…³é”®è¯åˆ—è¡¨
        lines.append(f"### å…³é”®è¯åˆ—è¡¨ï¼ˆå…± {len(keywords_dict)} ä¸ªï¼Œæ€»æƒé‡ {total_weight:.1f}ï¼‰")
        lines.append("")
        lines.append("| å…³é”®è¯ | æƒé‡ | ç±»å‹ |")
        lines.append("|--------|------|------|")
        for kw, weight in sorted(keywords_dict.items(), key=lambda x: x[1], reverse=True):
            kw_type = "ä¸»è¦" if weight >= 1.0 else "æ¬¡è¦"
            lines.append(f"| {kw} | {weight:.1f} | {kw_type} |")
        lines.append("")

        # è¯„åˆ†è®¾ç½®
        lines.append("### è¯„åˆ†è®¾ç½®")
        lines.append("")
        lines.append(f"- **æ¯ä¸ªå…³é”®è¯æœ€å¤§åˆ†**: {settings.MAX_SCORE_PER_KEYWORD}")
        lines.append(f"- **åŠæ ¼åˆ†å…¬å¼**: {settings.PASSING_SCORE_BASE} + {settings.PASSING_SCORE_WEIGHT_COEFFICIENT} Ã— æ€»æƒé‡")
        lines.append(f"- **å½“å‰åŠæ ¼åˆ†**: {passing_score:.1f}")
        if settings.ENABLE_AUTHOR_BONUS:
            lines.append(f"- **ä½œè€…åŠ åˆ†**: å¯ç”¨ï¼ˆ{settings.AUTHOR_BONUS_POINTS}åˆ†/ä¸“å®¶ï¼‰")
            if settings.EXPERT_AUTHORS:
                lines.append(f"- **ä¸“å®¶ä½œè€…**: {', '.join(settings.EXPERT_AUTHORS)}")
        lines.append("")

        return lines

    def _generate_stats_section(
        self,
        total_papers: int,
        qualified_count: int,
        analyzed_count: int,
        has_deep_analysis: bool
    ) -> List[str]:
        """ç”Ÿæˆç»Ÿè®¡æ±‡æ€»éƒ¨åˆ†"""
        lines = []
        lines.append("## ğŸ“ˆ è®ºæ–‡ç»Ÿè®¡")
        lines.append("")
        lines.append(f"- **æ€»æŠ“å–**: {total_papers} ç¯‡")
        if total_papers > 0:
            lines.append(f"- **åŠæ ¼è®ºæ–‡**: {qualified_count} ç¯‡ ({qualified_count / total_papers * 100:.1f}%)")
        else:
            lines.append(f"- **åŠæ ¼è®ºæ–‡**: {qualified_count} ç¯‡")
        if has_deep_analysis:
            lines.append(f"- **æ·±åº¦åˆ†æ**: {analyzed_count} ç¯‡")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _render_paper_section(
        self,
        paper: Dict[str, Any],
        keywords_dict: Dict[str, float],
        analyses: List[Dict[str, Any]],
        idx: int,
        is_qualified_section: bool = False,
        qualified_icon: str = "âœ…",
        unqualified_icon: str = "âŒ"
    ) -> List[str]:
        """
        ä½¿ç”¨æ¨¡å—åŒ–æ¸²æŸ“å™¨æ¸²æŸ“å•ç¯‡è®ºæ–‡ã€‚

        å‚æ•°:
            paper: è®ºæ–‡æ•°æ®
            keywords_dict: å…³é”®è¯å­—å…¸
            analyses: æ·±åº¦åˆ†æåˆ—è¡¨
            idx: åºå·
            is_qualified_section: æ˜¯å¦åœ¨åŠæ ¼è®ºæ–‡éƒ¨åˆ†
            qualified_icon: åŠæ ¼å›¾æ ‡
            unqualified_icon: æœªåŠæ ¼å›¾æ ‡

        è¿”å›:
            List[str]: æ¸²æŸ“åçš„è¡Œåˆ—è¡¨
        """
        lines = []
        score_resp = paper['score_response']
        paper_meta = paper.get('paper_metadata')

        # å‡†å¤‡æ•°æ®ï¼ˆæ·»åŠ keywords_dictä¾›scoringæ¨¡å—ä½¿ç”¨ï¼‰
        paper_data = {
            **paper,
            'keywords_dict': keywords_dict
        }

        # è·å–è®ºæ–‡æ ‡é¢˜ç”¨äºæ ‡é¢˜è¡Œ
        title = paper_meta.title if paper_meta else paper.get('title', 'Unknown')

        # ç”Ÿæˆæ ‡é¢˜è¡Œ
        if is_qualified_section:
            lines.append(f"### {idx}. {title[:100]}")
        else:
            status_icon = qualified_icon if score_resp.is_qualified else unqualified_icon
            lines.append(f"### {idx}. {status_icon} {title}")
        lines.append("")

        # è·å–æ¨¡å—é…ç½®
        modules = self.basic_template.get('modules', [])

        # ä½¿ç”¨æ¸²æŸ“å™¨å·¥å‚æ¸²æŸ“å„æ¨¡å—
        module_lines = self.renderer_factory.render_modules(paper_data, modules)
        lines.extend(module_lines)

        # å¦‚æœæ˜¯åŠæ ¼è®ºæ–‡éƒ¨åˆ†ï¼Œæ·»åŠ æ·±åº¦åˆ†æ
        if is_qualified_section and analyses:
            paper_id = paper_meta.paper_id if paper_meta else paper.get('paper_id')
            analysis = next((a['analysis'] for a in analyses if a['paper_id'] == paper_id), None)
            if analysis:
                analysis_data = {'analysis': analysis}
                analysis_lines = self.renderer_factory.get_renderer('deep_analysis').render(
                    analysis_data, {}
                )
                lines.extend(analysis_lines)

        lines.append("---")
        lines.append("")

        return lines

    # ==================== å‘åå…¼å®¹æ¥å£ ====================

    def generate_comprehensive_report(
        self,
        all_papers_with_scores: List[Dict[str, Any]],
        keywords_dict: Dict[str, float],
        qualified_papers_with_analysis: List[Dict[str, Any]] = None
    ):
        """
        ç”Ÿæˆç»¼åˆç ”ç©¶æŠ¥å‘Šï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰ã€‚

        æ­¤æ–¹æ³•ä¿ç•™ä»¥æ”¯æŒæ—§ç‰ˆä»£ç ï¼Œæ–°ä»£ç è¯·ä½¿ç”¨ generate_reports_by_source()ã€‚
        """
        # è½¬æ¢ä¸ºæ–°æ ¼å¼
        scored_papers_by_source = {"arxiv": all_papers_with_scores}
        analyses_by_source = {"arxiv": qualified_papers_with_analysis or []}

        self.generate_reports_by_source(
            scored_papers_by_source=scored_papers_by_source,
            keywords_dict=keywords_dict,
            analyses_by_source=analyses_by_source
        )
